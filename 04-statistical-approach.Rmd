---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
bib-humanities: true
documentclass: book
bibliography: [bibliography/references.bib, bibliography/additional-references.bib]
---

# General statistical approach {#chapter-stats}
\chaptermark{Statistics}

## Linear mixed effects models

As the name suggests, the linear mixed effects model (LME) is a linear regression model that consists of both fixed and random effects.
It allows modelling the underlying structure of the data, which includes
the standard fixed effects like the levels of speech degradation and the levels of target word predictability,
as well as random effects like items and participants.
These random effects are assumed to be random samples drawn from the general population.
In this thesis, the dependent variable (an *outcome* or a *response* variable) is binary (correct vs incorrect response).
So, we use binomial logistic mixed effects models with crossed random effects to model the data [@Baayen2008].

A linear mixed effects model can be written as:

  
\begin{align}
y = \alpha + u_{\alpha} + w_{\alpha} +
    (\beta_{1} + u_{\beta_{1}} + w_{\beta_{1}})\cdot {x_1} + \notag \\
    (\beta_{2} + u_{\beta_{2}} + w_{\beta_{2}})\cdot {x_2} + ... + \nonumber \\
    (\beta_{n} + u_{\beta_{n}} + w_{\beta_{n}})\cdot {x_n} (\#eq:mixed-effects1)
\end{align}
  

where,

- $y$ is the dependent variable, like participant's response (correct vs. incorrect)
- $\alpha$ is the Intercept.
- Fixed effects: $\beta_{1}, \beta_{2}, ..., \beta_{n}$ are the coefficients (or effects) of $x_1, x_2, ...,x_n$.
- $\boldsymbol{u} = \langle u_{\alpha}, u_{\beta_1}, u_{\beta_2}, ..., u_{\beta_n} \rangle$ : Varying intercept and slopes for random effect term like, *subject*.
- $\boldsymbol{w} = \langle w_{\alpha}, w_{\beta_1}, w_{\beta_2}, ..., w_{\beta_n} \rangle$ : Varying intercept and slopes for random effect term like, *item*.

In contrast to linear regression models, mixed effects models allow to simultaneously account for the effects of two random variables, like item and participants.
The variance in the categorical dependent variable is also preserved, which would otherwise be eliminated by averaging in linear regression models.
We discuss these issues and the motivation to use the mixed effects model in this thesis in more detail below in this chapter.

### Linear regression and its limitations

In linear regression, a dependent variable (or an *outcome*) is modelled as a function of one or more independent predictor variables (*factors* or *explanatory* variables).
That is, an outcome $y$ is modelled as a function of explanatory variables $x_1, x_2, x_3..., x_n$, and an error term $\varepsilon$.

  
\begin{align}
y =
\alpha + 
\beta_{1}\cdot{x_1} + 
\beta_{2}\cdot{x_2} + ... +
\beta_{n}\cdot{x_n} + \varepsilon (\#eq:linear-regression)
\end{align}
  

Analysis of Variance (ANOVA), also a form of linear regression [@Chatterjee2012; @Vasishth2022], compares the means and variances of two or more conditions.
As expressed in Equation \@ref(eq:linear-regression), regression models can only model fixed effects.
Although ANOVA can account for one random effect at a time, it still averages out the variance in the second random effect.
These problems of using ANOVA in language sciences have been pointed out as early as the 1960s [@Clark1973; @Coleman1964].
We elaborate on them in the context of the data of our experiments as follows.


#### Modeling two random effects simultaneously, and Variability in the data

As mentioned above, a simple linear regression model, including ANOVA, does not model the effect of two random effects simultaneously, which a mixed effects model does.
In the traditional ANOVA approach, researchers often run two separate regression models [@Lorch1990] by averaging raw data across participants, and items.
Averaging eliminates the variability in the data.
Additionally, comparing the means of a categorical variable (correct vs incorrect responses) even when transformed into accuracy or proportion scale is hard to interpret sensibly compared to a continuous variable like reaction time [for discussion, see @Bolker2009; @Jaeger2008].
The statistical remedy for these problems in analysing the data of our experiments is to apply mixed effects models.

#### Unbalanced data sets

In our studies, the data sets are unbalanced.
The experimental design is intended to result in a balanced data set.
However, after the removal of outliers and the trials that do not meet the inclusion criteria (for details, see Section \@ref(chapter-6-measurement)), the final data sets become unbalanced,
which introduces a bias in a regression model [@Jaeger2008].
A mixed effects model is best suited for such unbalanced data [@Baayen2008].

#### Common mean for each predictor

An intrinsic property or feature of the linear regression model is that it assumes a common mean for each predictor.
It has been shown that this is, in fact, not true in the actual data:
the effect of a predictor can vary depending on random variables like participant or item.
Mixed effects models take into account such inter-participant and inter-item variability present in the data.
For example, in mixed effects models,
the random effects term with only varying intercept, e.g., participant as an intercept, assumes that if there are 100 participants, then the mean accuracy of those 100 participants is only a subset of possible global accuracies drawn from a set of the population mean.
When a slope, e.g., levels of predictability, is included in the random effects structure in addition to the varying intercept (e.g., participants), then the model assumes that the effect of predictability on response accuracy varies across participants.
Such variance across participants (or across items) is present in the real data
and can be modelled in a mixed effects model but not in a linear regression model.

#### Bounded output variable, and Homogenity of variance

Linear models assume an output variable to be on a continuous scale and not be restricted in a narrow range.
In our data, the output variable has a binomially distributed binary outcome (correct or incorrect response) bounded on $[0,1]$.
For every trial, there is a probability $p$ (that ranges from 0 to 1) that the response will be correct, i.e. 1 (and a probability $1-p$ that the response will be incorrect, i.e. 0).

The variance of sample proportion is a function of $p$, which is shown below.

\begin{align} 
\sigma^2_p = \frac{p(1-p)}{n} (\#eq:variance)
\end{align}

That is, the variance of the sample proportions is highest at $p=0.5$;
it decreases symmetrically as $p$ approaches to 0 or 1.
Thus, for two samples with the proportions $p_1$ and $p_2$, the variances are similar if $p_1$ and $p_2$ are equidistant from 0.5.
Moreover, the further away $p_1$ and $p_2$ are from 0.5, the more dissimilar the variances will be, and the more it matters.
Critically, we do not know *a priori* what the value of $p$ is for different samples under consideration in our experiments.

In a linear model (like ANOVA), binary outcomes [0,1] can be transformed into a proportion scale across participants or across items.
Even though it is a continuous variable, the proportion scale (i.e., response accuracy) has a range (0,1).
Additionally, such a transformation of discrete variables brings a host of problems that we have already discussed above (e.g., loss of variability by averaging raw data).

Binomial logistic mixed effects models, on the other hand, transform[^logit-link-footnote] the output variable into a *logit* scale, $\log$ with base $e$, i.e. $\ln$, with a range $(-\infty, +\infty)$.
Therefore, these mixed effects models do not violate the model assumptions regarding the range of the outcome variables.
In addition, this transformation in the logistic model also capture the fact that the closer the sample proportions are to the 0.5 the less they matter [@Jaeger2008].

Thus, Equation \@ref(eq:mixed-effects1) can also be written as: 

  
\begin{align} 
\ln (\frac{p}{1-p}) = \alpha + u_{\alpha} + w_{\alpha} +
                      (\beta_{1} + u_{\beta_{1}} + w_{\beta_{1}})\cdot {x_1} + \nonumber\\
                      (\beta_{2} + u_{\beta_{2}} + w_{\beta_{2}})\cdot {x_2} + \nonumber\\
                      ... + (\beta_{n} + u_{\beta_{n}} + w_{\beta_{n}})\cdot {x_n} (\#eq:mixed-effects2)
\end{align}
  

This is equivalent to:

  
\begin{align} 
p = {\frac{exp(\ln(\frac{p}{1-p}))}{1 + exp (\ln(\frac{p}{1-p}))}} (\#eq:logit-to-prob)
\end{align}
  
 
where,

  
\begin{align} 
\ln(\frac{p}{1-p}) =
{logit}(p) (\#eq:logiteq)
\end{align}
  

Log-odds of correct response obtained from Equation \@ref(eq:mixed-effects2) can also be transformed into the probability of correct response.
Equations \@ref(eq:logit-to-prob) and \@ref(eq:logiteq) provide the relationship between probability, logits (or log-odds), and odds ($\frac{p}{1-p}$).  

We have presented the advantages of mixed effects models over linear (regression) models.
Hence, we used the binomial logistic mixed effects model as the statistical analysis tool in all experiments reported in this thesis.
Below we discuss how the model that best fits our data was selected.  

## Model selection and Running mixed effects models in R {#analysis-main}

The underlying structure of given data can be modelled by different approximate statistical models.
We intend to select a model that best fits our data.
'Best fit' can be objectively measured by Akaike Information Criterion, Bayesian Information Criterion, and Likelihood Ratio Test, among others [@Akaike1973; @Schwarz1978].

In this thesis, we first build a complex (or maximal) model
(e.g., by including all predictors, like target word predictability, speech degradation level, speech rate, their interactions, and co-variates, like trial number in the fixed effects)
that is justified by the experimental design [cf. @Bondell2010].
The model is fitted with a maximal random effects structure that includes random intercepts for each participant and item [@Barr2013].
By-participant and by-item slopes included in the model are discussed in the Analyses sections of Chapters 5, 6, and 7.  

Model selection was based on the backward-selection heuristics on the fixed effects [cf. @Matuschek2017].
To find the best fitting model for the data,
non-significant higher-order interactions were excluded from the fixed-effects structure in a stepwise manner.
Similarly, random effects not supported by the data that explained zero variance according to singular value decomposition were excluded to prevent overparameterisation [@Bates2015a].
This gave a more parsimonious model, which was then extended separately with: i) item-related correlation parameters, ii) participant-related correlation parameters, and iii) both item- and participant-related correlation parameters.
Among the parsimonious model and extended models,
the model with the smallest AIC was selected as the best fitting model for our data [@Grueber2011; @Richards2011].  

Data preprocessing and analyses were performed in R [@R2018] using R-Studio (Version 3.6.1, Version 3.6.3, and Version 4.1.3 at different time points).
Accuracy was analysed with Generalized Linear Mixed Models (GLMMs) with lmerTest [@Kuznetsova2017] and lme4 [@Bates2015] packages.
Binary responses (correct responses coded as 1 and incorrect responses coded as 0) for all participants were fit with a binomial logistic mixed effects model.
Contrast coding of each factor and the model description are presented in the Analyses section of the chapters that follow.

## Summary

In this chapter, we introduced the statistical tool used for data analysis in this thesis.
We discussed the limitations of traditional linear regression-based models like ANOVA
and outlined the motivations for using mixed effects models.
To capture the variability of our data without averaging out across participants or items,
and to account for the effect of two (or more) random effects --- participant and item --- simultaneously,
we fit mixed effects models to our data.  
Details of each data set corresponding to each experiment are presented in Chapters 5, 6, and 7.  


[^logit-link-footnote]: Such transformation is brought about in a generalized linear mixed effects model with a canonical logit link function [see @Malik2020 for discussion].  
